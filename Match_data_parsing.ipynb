{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMcAbwkU3eWU0Hu2iKcIMbj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/umutcanc7/DSA210-PROJECT-/blob/main/Match_data_parsing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MATCH DATA"
      ],
      "metadata": {
        "id": "36AaTuzbTWnK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import csv\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def fetch_match_data(url):\n",
        "    # Define headers to mimic a browser request (optional for some websites)\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36\"\n",
        "    }\n",
        "\n",
        "    # Send a GET request to the website\n",
        "    response = requests.get(url, headers=headers)\n",
        "\n",
        "    # Check if the request was successful\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Failed to fetch the page. Status code: {response.status_code}\")\n",
        "        return []\n",
        "\n",
        "    # Parse the HTML content with BeautifulSoup\n",
        "    html_content = response.text\n",
        "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
        "\n",
        "    # Locate the match data rows\n",
        "    table_rows = soup.select(\"tr\")\n",
        "    matches = []\n",
        "\n",
        "    # Iterate through the rows and extract relevant data\n",
        "    for row in table_rows:\n",
        "        # Find the score span inside the anchor tag with class 'ergebnis-link'\n",
        "        score_anchor = row.find(\"a\", class_=\"ergebnis-link\")\n",
        "        place_td = row.find_all(\"td\", class_=\"zentriert\")\n",
        "\n",
        "        if score_anchor and place_td:\n",
        "            # Extract the score\n",
        "            score = score_anchor.get_text(strip=True)\n",
        "\n",
        "            # Remove \"UZT\" if it exists in the right score\n",
        "            if \"UZT\" in score:\n",
        "                score = score.replace(\"UZT\", \"\").strip()\n",
        "\n",
        "            # Extract the place (E for home, D for away)\n",
        "            place = place_td[3].get_text(strip=True) if len(place_td) > 3 else \"N/A\"\n",
        "\n",
        "            # Initialize the result variable\n",
        "            result = \"N/A\"\n",
        "\n",
        "            # Check if it's a draw (both teams have the same score)\n",
        "            if \":\" in score:\n",
        "                score_parts = score.split(\":\")\n",
        "                if len(score_parts) == 2:\n",
        "                    left_score, right_score = score_parts[0], score_parts[1]\n",
        "\n",
        "                    # Determine the match result based on scores and location (home/away)\n",
        "                    if left_score == right_score:\n",
        "                        result = \"Draw\"\n",
        "                    elif place == \"E\":  # Home match\n",
        "                        result = \"Win\" if int(left_score) > int(right_score) else \"Loss\"\n",
        "                    elif place == \"D\":  # Away match\n",
        "                        result = \"Win\" if int(left_score) < int(right_score) else \"Loss\"\n",
        "\n",
        "            # Extract the date (only numeric part, without the day name)\n",
        "            date = place_td[1].get_text(strip=True) if len(place_td) > 1 else \"N/A\"\n",
        "            date_parts = date.split(\" \")  # Split by space\n",
        "            numeric_date = date_parts[-1]  # Get the last part as the numeric date\n",
        "\n",
        "            time = place_td[2].get_text(strip=True) if len(place_td) > 2 else \"N/A\"\n",
        "\n",
        "            # Create a dictionary for each match with specific columns\n",
        "            match_data = {\n",
        "                \"Date\": numeric_date,\n",
        "                \"Time\": time,\n",
        "                \"Score\": score,\n",
        "                \"Result\": result,\n",
        "            }\n",
        "            matches.append(match_data)\n",
        "\n",
        "    return matches\n",
        "\n",
        "def save_to_csv(data, filename):\n",
        "    # Define the column names for the CSV file\n",
        "    fieldnames = [\"Date\", \"Time\", \"Score\", \"Result\"]\n",
        "\n",
        "    # Open the CSV file in write mode and create a CSV DictWriter object\n",
        "    with open(filename, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
        "        writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
        "\n",
        "        # Write the header (column names)\n",
        "        writer.writeheader()\n",
        "\n",
        "        # Write each match's data in a row under the correct column\n",
        "        for match in data:\n",
        "            writer.writerow(match)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Replace with the URL of the webpage containing the match data\n",
        "    url = \"https://www.transfermarkt.com.tr/fenerbahce-istanbul/spielplandatum/verein/36\"  # Update with the correct URL\n",
        "\n",
        "    # Fetch match data\n",
        "    match_data = fetch_match_data(url)\n",
        "\n",
        "    if match_data:\n",
        "        print(\"Match Data Extracted and Saving to CSV...\")\n",
        "        # Save the extracted data to a CSV file\n",
        "        save_to_csv(match_data, \"match_data.csv\")\n",
        "        print(\"Data saved to match_data.csv\")\n",
        "    else:\n",
        "        print(\"No match data found.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1epJmFWTYaT",
        "outputId": "de2b4ebd-7c61-4b13-8289-06d427dd60e7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Match Data Extracted and Saving to CSV...\n",
            "Data saved to match_data.csv\n"
          ]
        }
      ]
    }
  ]
}